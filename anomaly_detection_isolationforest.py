# -*- coding: utf-8 -*-
"""Anomaly_detection_IsolationForest

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1dZdjEO86eyccGy2E9eQdAEy8IdSEQGG4
"""

###different types of anomalies - global/point, contextual, collective
###Contextual anomalies are difficult to identify, if the anomaly is a global/point anomaly - the datapoint will be completely outside \
###the distribution of the dataset.
###Contextual anomaly - A value has been effected because of an external influence. A normal pattern gets deviated in a context. The data \
##is abnormal to its previous seasonal pattern
###Timefactor is absent in Isolation forest, which is unlike ARIMA (where time factor is considered)
####Assuming Isolation forest is a non-time series model
####IsolationForest falls under unsupervised learning

import matplotlib as mpl
import matplotlib.pyplot as plt
import numpy as np
import os
from datetime import datetime
import pandas as pd
import plotly.express as px

from sklearn.ensemble import IsolationForest

mpl.rcParams['figure.figsize'] = (10, 8)
mpl.rcParams['axes.grid'] = False

import warnings
warnings.filterwarnings('ignore')

df = pd.read_csv('https://raw.githubusercontent.com/numenta/NAB/master/data/realKnownCause/nyc_taxi.csv')

df.info()

df['timestamp'] = pd.to_datetime(df['timestamp'])  ##converting date to timestamp
df = df.set_index('timestamp').resample("H").mean().reset_index()

fig = px.line(df.reset_index(), x='timestamp', y='value', title='NYC Taxi')

fig.update_xaxes(
    rangeslider_visible=True,
)
fig.show()

df['hour'] = df.timestamp.dt.hour
df['weekday'] = pd.Categorical(df.timestamp.dt.strftime('%A'),categories=['Monday','Tuesday','Wednesday','Thursday','Friday','Saturday','Sunday'])
df

df.info()

df[['hour','value']].groupby('hour').mean().plot()

df[['value','weekday']].groupby('weekday').mean().plot()

df.groupby(['hour', 'weekday']).mean()['value'].unstack().plot()

df.join(df.groupby(['hour','weekday'])['value'].mean(), on=['hour','weekday'],rsuffix='_avg')
df_final = df.join(df.groupby(['hour','weekday'])['value'].mean(), on=['hour','weekday'],rsuffix='_avg')

df_final

###Anomalous Point
# NYC marathon =  2014-11-02
# Thanksgiving = 2014-11-27
# Christmas = 2014-12-25
# New Years = 2015-01-01
# Snow Blizzard = 2015-01-26 & 2015-01-27

df_final.set_index('timestamp').loc['2014-11-02']

df_final.set_index('timestamp').loc['2015-01-26':'2015-01-27']

df_final['day']=df.timestamp.dt.weekday

df_final

data = df_final[['value','hour','day']]

data

model = IsolationForest(contamination=0.005, max_features=3, max_samples=0.8, n_estimators=200) ###One-hot encoding is not required in isolationforest, just numerical encoding
model.fit(data)

df_final['outliers'] = pd.Series(model.predict(data)).apply(lambda x:'yes' if (x == -1) else 'no')

df_final.query('outliers=="yes"')

fig = px.scatter(df_final, x='timestamp', y='value', color='outliers', hover_data=['weekday','hour','value_avg'], title="NYC TAXI")
fig.update_xaxes(
    rangeslider_visible=True
)
fig.show()

score=model.decision_function(data)

score

plt.hist(score, bins=50)

df_final['scores']=score

df_final

df_final.query('scores<-0.02')


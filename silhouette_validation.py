# -*- coding: utf-8 -*-
"""silhouette-validation

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1OoB4dgWZRQNhIcfPykXu2DG7o2khzvmB
"""

##silhouette coefficient which ranges from -1 to +1, usually done to determine accuracy, based on cohension(a) & separation(b)
from sklearn.datasets import make_blobs
from sklearn.cluster import KMeans
from sklearn.metrics import silhouette_samples, silhouette_score

import matplotlib.pyplot as plt
import matplotlib.cm as cm
import numpy as np

import warnings
warnings.filterwarnings("ignore")

"""Performance-metrics clustering"""

##Generating sample data from make_blobs
X, y = make_blobs(n_samples=500, n_features=2, centers=4, cluster_std=1, center_box=(-10.0,10.0), shuffle=True,\
                  random_state=1) #for reproducibility

range_n_clusters = [2,3,4,5,6]

from sklearn.cluster import KMeans

wcss =[]
for i in range(1,11):
  kmeans=KMeans(n_clusters=i, init='k-means++', random_state=0)
  kmeans.fit(X)
  wcss.append(kmeans.inertia_)

plt.plot(range(1,11),wcss)
plt.title('The elbow')
plt.xlabel('No. of clusters')
plt.ylabel('WCSS')
plt.show()

clusterer = KMeans(n_clusters=4, random_state=10)
cluster_labels = clusterer.fit_predict(X)
print(cluster_labels)

for n_clusters in range_n_clusters:
  ##create a subplot with 1 row and 2 columns
  fig, (ax1, ax2) = plt.subplots(1,2)
  fig.set_size_inches(18,7)

  ##the 1st plot is the silhouette plot
  ##the silhouette coeffiicent can range from -1,1
  ax1.set_xlim([-0.1,1])
  ##the (n_Clusters+1)*10 is for inserting blank space between silhouette
  ax1.set_ylim([0,len(X) + (n_clusters +1)* 10])

  ##initialize the clusterer wth n_clusters value and a random generator
  ##seed of 10 for reproducibility
  clusterer = KMeans(n_clusters=n_clusters, random_state=10)
  cluster_labels = clusterer.fit_predict(X)

##the silhouette_score gives the average value for all the samples
  silhouette_avg = silhouette_score(X, cluster_labels)
  print("for n_clusters", n_clusters, "The avg silhouette score:", silhouette_avg)

  ##compute the silhouette scores for each sample
  sample_silhouette_values = silhouette_samples(X, cluster_labels)

  y_lower = 10
  for i in range(n_clusters): ##aggregate the silhouette scores for samples belonging to cluster i, and sort them
     ith_cluster_silhouette_values = \
       sample_silhouette_values[cluster_labels == i]

     ith_cluster_silhouette_values.sort()

     size_cluster_i = ith_cluster_silhouette_values.shape[0]
     y_upper = y_lower + size_cluster_i

     color = cm.nipy_spectral(float(i) / n_clusters)
     ax1.fill_betweenx(np.arange(y_lower, y_upper),
                      0, ith_cluster_silhouette_values,
                      facecolor=color, edgecolor=color, alpha=0.7)

     ##label the silhouette plots with their cluster numbers at the middle
     ax1.text(-0.05, y_lower + 0.5 * size_cluster_i, str(i))

##compute the new y_lower for next plot
y_lower = y_upper + 10 #10 for the 0 samples

ax1.set_title("The silhouette score for the various clusters")
ax1.set_xlabel("The silhouette coefficient values")
ax1.set_ylabel("cluster label")

##the vertical like for average silhouette score of all the values
ax1.axvline(x=silhouette_avg, color="red", linestyle="--")

ax1.set_yticks([])
ax1.set_xticks([-0.1, 0, 0.2, 0.4, 0.6, 0.8, 1])

###2nd plot showing the actual cluster formed
colors = cm.nipy_spectral(cluster_labels.astype(float) / n_clusters)
ax2.scatter(X[:, 0], X[:, 1], marker='.', s=30, lw=0, alpha=0.7, c=colors, edgecolor='k')

##labelling the clusters
centers =clusterer.cluster_centers_
##draw the circle at cluster centers
ax1.scatter(centers[:,0], centers[:,1],marker='o', c='white', alpha=1, s=200, edgecolor='k')

for i, c in enumerate(centers):
    ax2.scatter(c[0], c[1], marker='$%d$' % i, alpha=1, s=50, edgecolor='k')

    ax2.set_title("Vizualization of the clustered data")
    ax2.set_xlabel("feature space for the 1st feature")
    ax2.set_ylabel("feature space for the 2nd feature")

  # plt.suptitle(("Silhouette analysis for KMeans clustering on sample data"))